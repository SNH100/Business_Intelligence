{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id label origin  age_range  gender\n",
      "0         34176         3906   0.0  train          6       0\n",
      "1         34176          121   0.0  train          6       0\n",
      "2         34176         4356   1.0  train          6       0\n",
      "3         34176         2217   0.0  train          6       0\n",
      "4        230784         4818   0.0  train          0       0\n",
      "...         ...          ...   ...    ...        ...     ...\n",
      "522336   228479         3111   nan   test          6       0\n",
      "522337    97919         2341   nan   test          8       1\n",
      "522338    97919         3971   nan   test          8       1\n",
      "522339    32639         3536   nan   test          0       0\n",
      "522340    32639         3319   nan   test          0       0\n",
      "\n",
      "[522341 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 用户行为，使用format1进行加载\n",
    "# 加载全量样本\n",
    "\n",
    "user_log = pd.read_csv('./user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('./user_info_format1.csv')\n",
    "train_data1 = pd.read_csv('./train_format1.csv')\n",
    "submission = pd.read_csv('./test_format1.csv')\n",
    "\n",
    "train_data = pd.read_csv('./train_format2.csv')\n",
    "\n",
    "train_data1['origin'] = 'train'\n",
    "submission['origin'] = 'test'\n",
    "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)\n",
    "#print(matrix)\n",
    "\n",
    "matrix.drop(['prob'], axis=1, inplace=True)\n",
    "# 连接user_info表，通过user_id关联\n",
    "matrix = matrix.merge(user_info, on='user_id', how='left')\n",
    "# 使用merchant_id（原列名seller_id）\n",
    "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\n",
    "# 格式化\n",
    "user_log['user_id'] = user_log['user_id'].astype('int32')\n",
    "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\n",
    "user_log['item_id'] = user_log['item_id'].astype('int32')\n",
    "user_log['cat_id'] = user_log['cat_id'].astype('int32')\n",
    "user_log['brand_id'].fillna(0, inplace=True)\n",
    "user_log['brand_id'] = user_log['brand_id'].astype('int32')\n",
    "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')\n",
    "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\n",
    "matrix['age_range'].fillna(0, inplace=True)\n",
    "# 0:female, 1:male, 2:unknown\n",
    "matrix['gender'].fillna(2, inplace=True)\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
    "del user_info, train_data1\n",
    "gc.collect()\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User特征处理\n",
    "groups = user_log.groupby(['user_id'])\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "#temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "# 对于每个user_id 不重复的item_id的数量 => u2\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "# 对于每个user_id 不重复的cat_id的数量 => u3\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 时间间隔特征 u6 按照小时\n",
    "# 对于每个user_id 计算time_stamp的最小时间 => F_time, 最大时间max => L_time\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "# 统计操作类型为0，1，2，3的个数\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# 商家特征处理\n",
    "groups = user_log.groupby(['merchant_id'])\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的action_type 唯一值\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 按照user_id, merchant_id分组\n",
    "groups = user_log.groupby(['user_id', 'merchant_id'])\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id label origin    u1    u2  u3   u4   u5        u6  \\\n",
      "0         34176         3906   0.0  train   451   256  45  109  108  5.833333   \n",
      "1         34176          121   0.0  train   451   256  45  109  108  5.833333   \n",
      "2         34176         4356   1.0  train   451   256  45  109  108  5.833333   \n",
      "3         34176         2217   0.0  train   451   256  45  109  108  5.833333   \n",
      "4        230784         4818   0.0  train    54    31  17   20   19  5.166667   \n",
      "...         ...          ...   ...    ...   ...   ...  ..  ...  ...       ...   \n",
      "522336   228479         3111   nan   test  2004  1173  71  278  282  6.000000   \n",
      "522337    97919         2341   nan   test    55    29  14   17   17  4.750000   \n",
      "522338    97919         3971   nan   test    55    29  14   17   17  4.750000   \n",
      "522339    32639         3536   nan   test    72    46  24   33   35  5.800000   \n",
      "522340    32639         3319   nan   test    72    46  24   33   35  5.800000   \n",
      "\n",
      "        ...  age_2  age_3  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \n",
      "0       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "1       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "2       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "3       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "4       ...      0      0      0      0      0      0      0    1    0    0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  ...  ...  ...  \n",
      "522336  ...      0      0      0      0      1      0      0    1    0    0  \n",
      "522337  ...      0      0      0      0      0      0      1    0    1    0  \n",
      "522338  ...      0      0      0      0      0      0      1    0    1    0  \n",
      "522339  ...      0      0      0      0      0      0      0    1    0    0  \n",
      "522340  ...      0      0      0      0      0      0      0    1    0    0  \n",
      "\n",
      "[522341 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "#用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "#商家购买点击比\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "#不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "matrix.fillna(0, inplace=True)\n",
    "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
    "del temp, matrix\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用机器学习工具\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "# 将训练集进行切分，20%用于验证\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.63451\tvalidation_1-auc:0.62780\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.65132\tvalidation_1-auc:0.63900\n",
      "[2]\tvalidation_0-auc:0.65764\tvalidation_1-auc:0.64451\n",
      "[3]\tvalidation_0-auc:0.66387\tvalidation_1-auc:0.64638\n",
      "[4]\tvalidation_0-auc:0.66539\tvalidation_1-auc:0.64907\n",
      "[5]\tvalidation_0-auc:0.66621\tvalidation_1-auc:0.64963\n",
      "[6]\tvalidation_0-auc:0.66744\tvalidation_1-auc:0.64929\n",
      "[7]\tvalidation_0-auc:0.66774\tvalidation_1-auc:0.64995\n",
      "[8]\tvalidation_0-auc:0.66858\tvalidation_1-auc:0.64997\n",
      "[9]\tvalidation_0-auc:0.66979\tvalidation_1-auc:0.65127\n",
      "[10]\tvalidation_0-auc:0.67073\tvalidation_1-auc:0.65066\n",
      "[11]\tvalidation_0-auc:0.67451\tvalidation_1-auc:0.65316\n",
      "[12]\tvalidation_0-auc:0.67539\tvalidation_1-auc:0.65380\n",
      "[13]\tvalidation_0-auc:0.67719\tvalidation_1-auc:0.65545\n",
      "[14]\tvalidation_0-auc:0.67958\tvalidation_1-auc:0.65720\n",
      "[15]\tvalidation_0-auc:0.68284\tvalidation_1-auc:0.66004\n",
      "[16]\tvalidation_0-auc:0.68385\tvalidation_1-auc:0.66014\n",
      "[17]\tvalidation_0-auc:0.68526\tvalidation_1-auc:0.66096\n",
      "[18]\tvalidation_0-auc:0.68673\tvalidation_1-auc:0.66133\n",
      "[19]\tvalidation_0-auc:0.68903\tvalidation_1-auc:0.66293\n",
      "[20]\tvalidation_0-auc:0.68980\tvalidation_1-auc:0.66247\n",
      "[21]\tvalidation_0-auc:0.69089\tvalidation_1-auc:0.66330\n",
      "[22]\tvalidation_0-auc:0.69217\tvalidation_1-auc:0.66341\n",
      "[23]\tvalidation_0-auc:0.69264\tvalidation_1-auc:0.66341\n",
      "[24]\tvalidation_0-auc:0.69423\tvalidation_1-auc:0.66474\n",
      "[25]\tvalidation_0-auc:0.69582\tvalidation_1-auc:0.66652\n",
      "[26]\tvalidation_0-auc:0.69659\tvalidation_1-auc:0.66690\n",
      "[27]\tvalidation_0-auc:0.69766\tvalidation_1-auc:0.66743\n",
      "[28]\tvalidation_0-auc:0.69883\tvalidation_1-auc:0.66800\n",
      "[29]\tvalidation_0-auc:0.70013\tvalidation_1-auc:0.66875\n",
      "[30]\tvalidation_0-auc:0.70104\tvalidation_1-auc:0.66940\n",
      "[31]\tvalidation_0-auc:0.70147\tvalidation_1-auc:0.66958\n",
      "[32]\tvalidation_0-auc:0.70248\tvalidation_1-auc:0.66952\n",
      "[33]\tvalidation_0-auc:0.70330\tvalidation_1-auc:0.67072\n",
      "[34]\tvalidation_0-auc:0.70449\tvalidation_1-auc:0.67165\n",
      "[35]\tvalidation_0-auc:0.70535\tvalidation_1-auc:0.67209\n",
      "[36]\tvalidation_0-auc:0.70571\tvalidation_1-auc:0.67259\n",
      "[37]\tvalidation_0-auc:0.70660\tvalidation_1-auc:0.67191\n",
      "[38]\tvalidation_0-auc:0.70723\tvalidation_1-auc:0.67240\n",
      "[39]\tvalidation_0-auc:0.70778\tvalidation_1-auc:0.67267\n",
      "[40]\tvalidation_0-auc:0.70862\tvalidation_1-auc:0.67263\n",
      "[41]\tvalidation_0-auc:0.70895\tvalidation_1-auc:0.67234\n",
      "[42]\tvalidation_0-auc:0.70969\tvalidation_1-auc:0.67250\n",
      "[43]\tvalidation_0-auc:0.71009\tvalidation_1-auc:0.67246\n",
      "[44]\tvalidation_0-auc:0.71053\tvalidation_1-auc:0.67291\n",
      "[45]\tvalidation_0-auc:0.71135\tvalidation_1-auc:0.67345\n",
      "[46]\tvalidation_0-auc:0.71206\tvalidation_1-auc:0.67342\n",
      "[47]\tvalidation_0-auc:0.71267\tvalidation_1-auc:0.67372\n",
      "[48]\tvalidation_0-auc:0.71317\tvalidation_1-auc:0.67325\n",
      "[49]\tvalidation_0-auc:0.71350\tvalidation_1-auc:0.67353\n",
      "[50]\tvalidation_0-auc:0.71390\tvalidation_1-auc:0.67335\n",
      "[51]\tvalidation_0-auc:0.71472\tvalidation_1-auc:0.67345\n",
      "[52]\tvalidation_0-auc:0.71517\tvalidation_1-auc:0.67336\n",
      "[53]\tvalidation_0-auc:0.71589\tvalidation_1-auc:0.67353\n",
      "[54]\tvalidation_0-auc:0.71691\tvalidation_1-auc:0.67353\n",
      "[55]\tvalidation_0-auc:0.71719\tvalidation_1-auc:0.67323\n",
      "[56]\tvalidation_0-auc:0.71786\tvalidation_1-auc:0.67352\n",
      "[57]\tvalidation_0-auc:0.71831\tvalidation_1-auc:0.67371\n",
      "Stopping. Best iteration:\n",
      "[47]\tvalidation_0-auc:0.71267\tvalidation_1-auc:0.67372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用XGBoost\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42    \n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_metric='auc', eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=True,\n",
    "    #早停法，如果auc在10epoch没有进步就stop\n",
    "    early_stopping_rounds=10 \n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prob = model.predict_proba(test_data)\n",
    "submission['prob'] = pd.Series(prob[:,1])\n",
    "submission.drop(['origin'], axis=1, inplace=True)\n",
    "submission.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户行为，使用format1进行加载\n",
    "# 加载全量样本\n",
    "\n",
    "user_log = pd.read_csv('./user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('./user_info_format1.csv')\n",
    "train_data1 = pd.read_csv('./train_format1.csv')\n",
    "submission = pd.read_csv('./test_format1.csv')\n",
    "train_data = pd.read_csv('./train_format2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1['origin'] = 'train'\n",
    "submission['origin'] = 'test'\n",
    "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用merchant_id（原列名seller_id）\n",
    "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\n",
    "# 格式化\n",
    "user_log['user_id'] = user_log['user_id'].astype('int32')\n",
    "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\n",
    "user_log['item_id'] = user_log['item_id'].astype('int32')\n",
    "user_log['cat_id'] = user_log['cat_id'].astype('int32')\n",
    "user_log['brand_id'].fillna(0, inplace=True)\n",
    "user_log['brand_id'] = user_log['brand_id'].astype('int32')\n",
    "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对离散特征做LabelEncoder\n",
    "lbe_merchant_id=LabelEncoder()\n",
    "lbe_merchant_id.fit(np.r_[0,user_log['merchant_id'].values])\n",
    "user_log['merchant_id']=lbe_merchant_id.transform(user_log['merchant_id'])\n",
    "matrix['merchant_id']=lbe_merchant_id.transform(matrix['merchant_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe_user_id=LabelEncoder()\n",
    "user_log['user_id']=lbe_user_id.fit_transform(user_log['user_id'])\n",
    "user_info['user_id']=lbe_user_id.transform(user_info['user_id'])\n",
    "matrix['user_id']=lbe_user_id.transform(matrix['user_id'])\n",
    "\n",
    "lbe_item_id=LabelEncoder()\n",
    "user_log['item_id']=lbe_item_id.fit_transform(user_log['item_id'])\n",
    "lbe_cat_id=LabelEncoder()\n",
    "user_log['cat_id']=lbe_cat_id.fit_transform(user_log['cat_id'])\n",
    "lbe_brand_id=LabelEncoder()\n",
    "user_log['brand_id']=lbe_brand_id.fit_transform(user_log['brand_id'])\n",
    "\n",
    "user_log['merchant_id'].max(),user_log['user_id'].max()\n",
    "matrix = matrix.merge(user_info, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id label origin  prob  age_range  gender\n",
      "0         34175         3906   0.0  train   NaN          6       0\n",
      "1         34175          121   0.0  train   NaN          6       0\n",
      "2         34175         4356   1.0  train   NaN          6       0\n",
      "3         34175         2217   0.0  train   NaN          6       0\n",
      "4        230783         4818   0.0  train   NaN          0       0\n",
      "...         ...          ...   ...    ...   ...        ...     ...\n",
      "522336   228478         3111   nan   test   NaN          6       0\n",
      "522337    97918         2341   nan   test   NaN          8       1\n",
      "522338    97918         3971   nan   test   NaN          8       1\n",
      "522339    32638         3536   nan   test   NaN          0       0\n",
      "522340    32638         3319   nan   test   NaN          0       0\n",
      "\n",
      "[522341 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\n",
    "matrix['age_range'].fillna(0, inplace=True)\n",
    "# 0:female, 1:male, 2:unknown\n",
    "matrix['gender'].fillna(2, inplace=True)\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
    "del user_info, train_data1\n",
    "gc.collect()\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User特征处理\n",
    "groups = user_log.groupby(['user_id'])\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "#temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id label origin  prob  age_range  gender    u1  \\\n",
      "0         34175         3906   0.0  train   NaN          6       0   451   \n",
      "1         34175          121   0.0  train   NaN          6       0   451   \n",
      "2         34175         4356   1.0  train   NaN          6       0   451   \n",
      "3         34175         2217   0.0  train   NaN          6       0   451   \n",
      "4        230783         4818   0.0  train   NaN          0       0    54   \n",
      "...         ...          ...   ...    ...   ...        ...     ...   ...   \n",
      "522336   228478         3111   nan   test   NaN          6       0  2004   \n",
      "522337    97918         2341   nan   test   NaN          8       1    55   \n",
      "522338    97918         3971   nan   test   NaN          8       1    55   \n",
      "522339    32638         3536   nan   test   NaN          0       0    72   \n",
      "522340    32638         3319   nan   test   NaN          0       0    72   \n",
      "\n",
      "          u2  u3   u4   u5        u6      u7   u8    u9    u10  \n",
      "0        256  45  109  108  5.833333   410.0  NaN  34.0    7.0  \n",
      "1        256  45  109  108  5.833333   410.0  NaN  34.0    7.0  \n",
      "2        256  45  109  108  5.833333   410.0  NaN  34.0    7.0  \n",
      "3        256  45  109  108  5.833333   410.0  NaN  34.0    7.0  \n",
      "4         31  17   20   19  5.166667    47.0  NaN   7.0    NaN  \n",
      "...      ...  ..  ...  ...       ...     ...  ...   ...    ...  \n",
      "522336  1173  71  278  282  6.000000  1770.0  NaN  26.0  208.0  \n",
      "522337    29  14   17   17  4.750000    46.0  NaN   8.0    1.0  \n",
      "522338    29  14   17   17  4.750000    46.0  NaN   8.0    1.0  \n",
      "522339    46  24   33   35  5.800000    62.0  1.0   8.0    1.0  \n",
      "522340    46  24   33   35  5.800000    62.0  1.0   8.0    1.0  \n",
      "\n",
      "[522341 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# 时间间隔特征 u6 按照小时\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "# 统计action_type为0，1，2，3的个数（原始操作，没有补0）\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id label origin  prob  age_range  gender    u1  \\\n",
      "0         34175         3906   0.0  train   NaN          6       0   451   \n",
      "1         34175          121   0.0  train   NaN          6       0   451   \n",
      "2         34175         4356   1.0  train   NaN          6       0   451   \n",
      "3         34175         2217   0.0  train   NaN          6       0   451   \n",
      "4        230783         4818   0.0  train   NaN          0       0    54   \n",
      "...         ...          ...   ...    ...   ...        ...     ...   ...   \n",
      "522336   228478         3111   nan   test   NaN          6       0  2004   \n",
      "522337    97918         2341   nan   test   NaN          8       1    55   \n",
      "522338    97918         3971   nan   test   NaN          8       1    55   \n",
      "522339    32638         3536   nan   test   NaN          0       0    72   \n",
      "522340    32638         3319   nan   test   NaN          0       0    72   \n",
      "\n",
      "          u2  u3  ...     m1     m2    m3   m4  m5       m6     m7      m8  \\\n",
      "0        256  45  ...  16269   5819   308   20   2  14870.0   28.0   410.0   \n",
      "1        256  45  ...  79865  10931  1179   26   2  72265.0  121.0  4780.0   \n",
      "2        256  45  ...   7269   2281    67   15   2   6094.0   16.0   963.0   \n",
      "3        256  45  ...  60202  16870   377    5   2  52230.0  101.0  3721.0   \n",
      "4         31  17  ...  48089   7500   461   27   2  43268.0  129.0  2733.0   \n",
      "...      ...  ..  ...    ...    ...   ...  ...  ..      ...    ...     ...   \n",
      "522336  1173  71  ...  10105   4154   542   50  18   8997.0    9.0   687.0   \n",
      "522337    29  14  ...   5543   1592   352   93  19   4548.0    6.0   815.0   \n",
      "522338    29  14  ...  28892   7587   272    7   2  24602.0   94.0  2608.0   \n",
      "522339    46  24  ...  14027   4956   322   19   3  12807.0   29.0   793.0   \n",
      "522340    46  24  ...  25959   7927   952  175  85  21737.0   34.0  2700.0   \n",
      "\n",
      "            m9   m10  \n",
      "0        961.0  2861  \n",
      "1       2699.0  4530  \n",
      "2        196.0  1088  \n",
      "3       4150.0  7268  \n",
      "4       1959.0  3102  \n",
      "...        ...   ...  \n",
      "522336   412.0  1982  \n",
      "522337   174.0   703  \n",
      "522338  1588.0  3050  \n",
      "522339   398.0  2177  \n",
      "522340  1488.0  3607  \n",
      "\n",
      "[522341 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# 商家特征处理\n",
    "groups = user_log.groupby(['merchant_id'])\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的action_type 唯一值\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id  merchant_id  um9\n",
      "0               0          471  0.0\n",
      "1               0          739  0.0\n",
      "2               0          925  0.0\n",
      "3               0         1019  0.0\n",
      "4               0         1156  0.0\n",
      "...           ...          ...  ...\n",
      "14058661   424169         1082  0.0\n",
      "14058662   424169         3469  0.0\n",
      "14058663   424169         3736  0.0\n",
      "14058664   424169         4268  0.1\n",
      "14058665   424169         4963  0.0\n",
      "\n",
      "[14058666 rows x 3 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "        user_id  merchant_id label origin  prob  age_range  gender    u1  \\\n",
      "0         34175         3906   0.0  train   NaN          6       0   451   \n",
      "1         34175          121   0.0  train   NaN          6       0   451   \n",
      "2         34175         4356   1.0  train   NaN          6       0   451   \n",
      "3         34175         2217   0.0  train   NaN          6       0   451   \n",
      "4        230783         4818   0.0  train   NaN          0       0    54   \n",
      "...         ...          ...   ...    ...   ...        ...     ...   ...   \n",
      "522336   228478         3111   nan   test   NaN          6       0  2004   \n",
      "522337    97918         2341   nan   test   NaN          8       1    55   \n",
      "522338    97918         3971   nan   test   NaN          8       1    55   \n",
      "522339    32638         3536   nan   test   NaN          0       0    72   \n",
      "522340    32638         3319   nan   test   NaN          0       0    72   \n",
      "\n",
      "          u2  u3  ...   m10  um1  um2  um3  um4   um5  um6  um7  um8       um9  \n",
      "0        256  45  ...  2861   39   20    6    1  36.0  NaN  1.0  2.0  0.850000  \n",
      "1        256  45  ...  4530   14    1    1    1  13.0  NaN  1.0  NaN  0.050000  \n",
      "2        256  45  ...  1088   18    2    1    1  12.0  NaN  6.0  NaN  0.016667  \n",
      "3        256  45  ...  7268    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
      "4         31  17  ...  3102    8    1    1    1   7.0  NaN  1.0  NaN  0.050000  \n",
      "...      ...  ..  ...   ...  ...  ...  ...  ...   ...  ...  ...  ...       ...  \n",
      "522336  1173  71  ...  1982    5    2    1    1   4.0  NaN  1.0  NaN  0.016667  \n",
      "522337    29  14  ...   703    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
      "522338    29  14  ...  3050   16    5    2    1  12.0  NaN  4.0  NaN  0.150000  \n",
      "522339    46  24  ...  2177    3    2    1    1   2.0  NaN  1.0  NaN  0.000000  \n",
      "522340    46  24  ...  3607   11    1    1    1  10.0  NaN  1.0  NaN  0.016667  \n",
      "\n",
      "[522341 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# 按照user_id, merchant_id分组\n",
    "groups = user_log.groupby(['user_id', 'merchant_id'])\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "print(temp)\n",
    "print('-'*100)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id label origin  prob    u1    u2  u3   u4   u5  \\\n",
      "0         34175         3906   0.0  train   0.0   451   256  45  109  108   \n",
      "1         34175          121   0.0  train   0.0   451   256  45  109  108   \n",
      "2         34175         4356   1.0  train   0.0   451   256  45  109  108   \n",
      "3         34175         2217   0.0  train   0.0   451   256  45  109  108   \n",
      "4        230783         4818   0.0  train   0.0    54    31  17   20   19   \n",
      "...         ...          ...   ...    ...   ...   ...   ...  ..  ...  ...   \n",
      "522336   228478         3111   nan   test   0.0  2004  1173  71  278  282   \n",
      "522337    97918         2341   nan   test   0.0    55    29  14   17   17   \n",
      "522338    97918         3971   nan   test   0.0    55    29  14   17   17   \n",
      "522339    32638         3536   nan   test   0.0    72    46  24   33   35   \n",
      "522340    32638         3319   nan   test   0.0    72    46  24   33   35   \n",
      "\n",
      "        ...  age_2  age_3  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \n",
      "0       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "1       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "2       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "3       ...      0      0      0      0      1      0      0    1    0    0  \n",
      "4       ...      0      0      0      0      0      0      0    1    0    0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  ...  ...  ...  \n",
      "522336  ...      0      0      0      0      1      0      0    1    0    0  \n",
      "522337  ...      0      0      0      0      0      0      1    0    1    0  \n",
      "522338  ...      0      0      0      0      0      0      1    0    1    0  \n",
      "522339  ...      0      0      0      0      0      0      0    1    0    0  \n",
      "522340  ...      0      0      0      0      0      0      0    1    0    0  \n",
      "\n",
      "[522341 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "#用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "#商家购买点击比\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "#不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "matrix.fillna(0, inplace=True)\n",
    "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id label origin  prob    u1    u2  u3   u4   u5  \\\n",
      "0         34175         3906   0.0  train   0.0   451   256  45  109  108   \n",
      "1         34175          121   0.0  train   0.0   451   256  45  109  108   \n",
      "2         34175         4356   1.0  train   0.0   451   256  45  109  108   \n",
      "3         34175         2217   0.0  train   0.0   451   256  45  109  108   \n",
      "4        230783         4818   0.0  train   0.0    54    31  17   20   19   \n",
      "...         ...          ...   ...    ...   ...   ...   ...  ..  ...  ...   \n",
      "522336   228478         3111   nan   test   0.0  2004  1173  71  278  282   \n",
      "522337    97918         2341   nan   test   0.0    55    29  14   17   17   \n",
      "522338    97918         3971   nan   test   0.0    55    29  14   17   17   \n",
      "522339    32638         3536   nan   test   0.0    72    46  24   33   35   \n",
      "522340    32638         3319   nan   test   0.0    72    46  24   33   35   \n",
      "\n",
      "        ...  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \\\n",
      "0       ...      0      0      1      0      0    1    0    0   \n",
      "1       ...      0      0      1      0      0    1    0    0   \n",
      "2       ...      0      0      1      0      0    1    0    0   \n",
      "3       ...      0      0      1      0      0    1    0    0   \n",
      "4       ...      0      0      0      0      0    1    0    0   \n",
      "...     ...    ...    ...    ...    ...    ...  ...  ...  ...   \n",
      "522336  ...      0      0      1      0      0    1    0    0   \n",
      "522337  ...      0      0      0      0      1    0    1    0   \n",
      "522338  ...      0      0      0      0      1    0    1    0   \n",
      "522339  ...      0      0      0      0      0    1    0    0   \n",
      "522340  ...      0      0      0      0      0    1    0    0   \n",
      "\n",
      "                                         hist_merchant_id  \\\n",
      "0       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "1       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "2       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "3       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "4       [376, 3904, 3556, 3556, 3556, 3556, 3556, 3556...   \n",
      "...                                                   ...   \n",
      "522336  [4094, 4143, 527, 4143, 4143, 571, 527, 4143, ...   \n",
      "522337  [235, 3971, 3971, 3971, 3971, 2341, 2993, 2341...   \n",
      "522338  [235, 3971, 3971, 3971, 3971, 2341, 2993, 2341...   \n",
      "522339  [2702, 2550, 2550, 38, 1890, 2616, 1506, 2550,...   \n",
      "522340  [2702, 2550, 2550, 38, 1890, 2616, 1506, 2550,...   \n",
      "\n",
      "                                         hist_action_type  \n",
      "0       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 3, ...  \n",
      "...                                                   ...  \n",
      "522336  [1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, ...  \n",
      "522337  [1, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, ...  \n",
      "522338  [1, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, ...  \n",
      "522339  [1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "522340  [1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "\n",
      "[522341 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "lbe_action_type={0:1,1:2,2:3,3:4}\n",
    "user_log['action_type']=user_log['action_type'].map(lbe_action_type)\n",
    "# 用户行为sequence\n",
    "# 把user_log里同user的这些数据合并成一个list\n",
    "temp=pd.DataFrame(user_log.groupby('user_id')['merchant_id','action_type'].agg(lambda x:list(x)))\n",
    "# 列名称改成hist_merchant_id 和 hist_action_type \n",
    "temp.columns=['hist_merchant_id','hist_action_type']\n",
    "#print(temp)\n",
    "matrix = matrix.merge(temp, on=['user_id'], how='left') #统计时间间隔\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  merchant_id  prob   u1   u2  u3   u4   u5        u6     u7  \\\n",
      "0         34175         3906   0.0  451  256  45  109  108  5.833333  410.0   \n",
      "1         34175          121   0.0  451  256  45  109  108  5.833333  410.0   \n",
      "2         34175         4356   0.0  451  256  45  109  108  5.833333  410.0   \n",
      "3         34175         2217   0.0  451  256  45  109  108  5.833333  410.0   \n",
      "4        230783         4818   0.0   54   31  17   20   19  5.166667   47.0   \n",
      "...         ...          ...   ...  ...  ...  ..  ...  ...       ...    ...   \n",
      "260859   359806         4325   0.0  117   49  25   33   32  1.850000  107.0   \n",
      "260860   294526         3971   0.0  198   89  20   38   37  1.766667  162.0   \n",
      "260861   294526          152   0.0  198   89  20   38   37  1.766667  162.0   \n",
      "260862   294526         2537   0.0  198   89  20   38   37  1.766667  162.0   \n",
      "260863   229246         4140   0.0  194  127  29   50   49  5.916667  181.0   \n",
      "\n",
      "        ...  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \\\n",
      "0       ...      0      0      1      0      0    1    0    0   \n",
      "1       ...      0      0      1      0      0    1    0    0   \n",
      "2       ...      0      0      1      0      0    1    0    0   \n",
      "3       ...      0      0      1      0      0    1    0    0   \n",
      "4       ...      0      0      0      0      0    1    0    0   \n",
      "...     ...    ...    ...    ...    ...    ...  ...  ...  ...   \n",
      "260859  ...      1      0      0      0      0    0    1    0   \n",
      "260860  ...      0      0      0      0      0    0    1    0   \n",
      "260861  ...      0      0      0      0      0    0    1    0   \n",
      "260862  ...      0      0      0      0      0    0    1    0   \n",
      "260863  ...      1      0      0      0      0    0    0    1   \n",
      "\n",
      "                                         hist_merchant_id  \\\n",
      "0       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "1       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "2       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "3       [4231, 1945, 3700, 2179, 1875, 3001, 1815, 331...   \n",
      "4       [376, 3904, 3556, 3556, 3556, 3556, 3556, 3556...   \n",
      "...                                                   ...   \n",
      "260859  [3186, 4867, 1427, 4516, 1427, 4867, 744, 744,...   \n",
      "260860  [3971, 3022, 4059, 4976, 4372, 974, 4760, 4976...   \n",
      "260861  [3971, 3022, 4059, 4976, 4372, 974, 4760, 4976...   \n",
      "260862  [3971, 3022, 4059, 4976, 4372, 974, 4760, 4976...   \n",
      "260863  [4140, 858, 4140, 858, 858, 3449, 858, 2082, 8...   \n",
      "\n",
      "                                         hist_action_type  \n",
      "0       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 3, ...  \n",
      "...                                                   ...  \n",
      "260859  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "260860  [1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, ...  \n",
      "260861  [1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, ...  \n",
      "260862  [1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, ...  \n",
      "260863  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "\n",
      "[260864 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# 截取，不缺到定长M个\n",
    "M=500\n",
    "for feature in ['hist_merchant_id','hist_action_type']:\n",
    "    matrix[feature]=matrix[feature].map(lambda x:np.array(x+[0]*(M-len(x)))[:M])\n",
    "\n",
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用DIN模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat,get_feature_names\n",
    "from deepctr.models import DIN, DIEN, DSIN\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "212062\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "merchant_id\n",
      "1993\n",
      "prob\n",
      "1\n",
      "u1\n",
      "1793\n",
      "u2\n",
      "1117\n",
      "u3\n",
      "193\n",
      "u4\n",
      "425\n",
      "u5\n",
      "418\n",
      "u6\n",
      "186\n",
      "u7\n",
      "1704\n",
      "u8\n",
      "23\n",
      "u9\n",
      "133\n",
      "u10\n",
      "351\n",
      "m1\n",
      "1855\n",
      "m2\n",
      "1596\n",
      "m3\n",
      "562\n",
      "m4\n",
      "92\n",
      "m5\n",
      "53\n",
      "m6\n",
      "1822\n",
      "m7\n",
      "130\n",
      "m8\n",
      "1008\n",
      "m9\n",
      "879\n",
      "m10\n",
      "1360\n",
      "um1\n",
      "360\n",
      "um2\n",
      "184\n",
      "um3\n",
      "31\n",
      "um4\n",
      "19\n",
      "um5\n",
      "359\n",
      "um6\n",
      "12\n",
      "um7\n",
      "10\n",
      "um8\n",
      "52\n",
      "um9\n",
      "185\n",
      "r1\n",
      "12521\n",
      "r2\n",
      "1988\n",
      "r3\n",
      "1018\n",
      "age_0\n",
      "2\n",
      "age_1\n",
      "2\n",
      "age_2\n",
      "2\n",
      "age_3\n",
      "2\n",
      "age_4\n",
      "2\n",
      "age_5\n",
      "2\n",
      "age_6\n",
      "2\n",
      "age_7\n",
      "2\n",
      "age_8\n",
      "2\n",
      "g_0\n",
      "2\n",
      "g_1\n",
      "2\n",
      "g_2\n",
      "2\n",
      "action_type\n",
      "1\n",
      "(260864,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "260864"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['action_type']=3\n",
    "feature_columns = []\n",
    "for column in train_X.columns:\n",
    "  if column != 'hist_merchant_id' and column != 'hist_action_type':\n",
    "    print(column)\n",
    "    num = train_X[column].nunique()\n",
    "    if num > 10000:\n",
    "        dim = 10\n",
    "    else:\n",
    "        if num > 1000:\n",
    "            dim = 8\n",
    "        else:\n",
    "            dim = 4\n",
    "    print(num)\n",
    "    if column  == 'user_id':\n",
    "        feature_columns += [SparseFeat(column, 424169+1, embedding_dim=dim)]\n",
    "    elif column  == 'merchant_id':\n",
    "        feature_columns += [SparseFeat(column, 5007+1, embedding_dim=dim)]\n",
    "    elif column  == 'action_type':\n",
    "        feature_columns += [SparseFeat(column, 4+1, embedding_dim=dim)]\n",
    "    else:\n",
    "        feature_columns += [DenseFeat(column, 1)]\n",
    "\n",
    "print(train_X['hist_merchant_id'].shape)\n",
    "len(train_X['hist_merchant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 500\n"
     ]
    }
   ],
   "source": [
    "print('M=', M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseFeat(name='user_id', vocabulary_size=424170, embedding_dim=10, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f45232e5490>, embedding_name='user_id', group_name='default_group', trainable=True), SparseFeat(name='merchant_id', vocabulary_size=5008, embedding_dim=8, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f45225bd790>, embedding_name='merchant_id', group_name='default_group', trainable=True), DenseFeat(name='prob', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u9', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='u10', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m9', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='m10', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='um9', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='r1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='r2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='r3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_0', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_2', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_3', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_4', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_5', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_6', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_7', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='age_8', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='g_0', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='g_1', dimension=1, dtype='float32', transform_fn=None), DenseFeat(name='g_2', dimension=1, dtype='float32', transform_fn=None), SparseFeat(name='action_type', vocabulary_size=5, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f45225d4890>, embedding_name='action_type', group_name='default_group', trainable=True), VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_merchant_id', vocabulary_size=5008, embedding_dim=8, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f45225830d0>, embedding_name='merchant_id', group_name='default_group', trainable=True), maxlen=500, combiner='mean', length_name=None, weight_name=None, weight_norm=True), VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_action_type', vocabulary_size=5, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x7f4522583110>, embedding_name='action_type', group_name='default_group', trainable=True), maxlen=500, combiner='mean', length_name=None, weight_name=None, weight_norm=True)]\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260864/260864 [00:00<00:00, 727902.93it/s]\n",
      "100%|██████████| 260864/260864 [00:00<00:00, 1232405.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408/408 [==============================] - 198s 486ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 2/10\n",
      "408/408 [==============================] - 152s 373ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 3/10\n",
      "408/408 [==============================] - 152s 372ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 4/10\n",
      "408/408 [==============================] - 152s 372ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 5/10\n",
      "408/408 [==============================] - 151s 369ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 6/10\n",
      "408/408 [==============================] - 152s 373ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 7/10\n",
      "408/408 [==============================] - 151s 371ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 8/10\n",
      "408/408 [==============================] - 160s 392ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 9/10\n",
      "408/408 [==============================] - 168s 412ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n",
      "Epoch 10/10\n",
      "408/408 [==============================] - 163s 400ms/step - loss: 14.3168 - binary_crossentropy: 14.3168 - val_loss: 14.3169 - val_binary_crossentropy: 14.3169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261477/261477 [00:00<00:00, 1116830.38it/s]\n",
      "100%|██████████| 261477/261477 [00:00<00:00, 2426143.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# maxlen为历史信息的长度，vocabulary_size为onehot的长度\n",
    "feature_columns += [VarLenSparseFeat(SparseFeat('hist_merchant_id',vocabulary_size=5007+1, embedding_dim=8, embedding_name='merchant_id'),maxlen=M),\n",
    "                   VarLenSparseFeat(SparseFeat('hist_action_type',  vocabulary_size=4+1, embedding_dim=4, embedding_name='action_type'),maxlen=M)]\n",
    "hist_features=['merchant_id','action_type']\n",
    "print(feature_columns)\n",
    "\n",
    "# 使用DIN模型\n",
    "model=DIN(feature_columns, hist_features)\n",
    "# 使用Adam优化器，二分类的交叉熵\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['binary_crossentropy'])\n",
    "\n",
    "# 组装train_model_input，得到feature names，将train_X转换为字典格式\n",
    "feature_names=list(train_X.columns)\n",
    "train_model_input = {name:train_X[name].values for name in feature_names}\n",
    "# histroy输入必须是二维数组\n",
    "from tqdm import tqdm\n",
    "for fea in ['hist_merchant_id','hist_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(train_model_input[fea]):\n",
    "        l.append(i)\n",
    "    train_model_input[fea]=np.array(l)\n",
    "history = model.fit(train_model_input, train_y.map(float), verbose=True, epochs=10, validation_split=0.2,batch_size=512)\n",
    "\n",
    "# 转换test__model_input\n",
    "test_data['action_type']=3\n",
    "test_model_input = {name:test_data[name].values for name in feature_names}\n",
    "from tqdm import tqdm\n",
    "for fea in ['hist_merchant_id','hist_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(test_model_input[fea]):\n",
    "        l.append(i)\n",
    "    test_model_input[fea]=np.array(l)\n",
    "\n",
    "# 得到预测结果\n",
    "prob = model.predict(test_model_input)\n",
    "submission['prob'] = prob\n",
    "submission.drop(['origin'], axis=1, inplace=True)\n",
    "submission.to_csv('prediction_GIN.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

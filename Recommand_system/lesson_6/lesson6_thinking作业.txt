###Thinking1:在实际工作中，FM和MF哪个应用的更多，为什么?

FM因子分解机使用的更多,原因是FM的泛化能力更强.FM内置了MF,所以它的功能更加强大.再详细一点说,就是MF只能解决2维维度的问题:即userID,itemID
但是实际场景中n维特征向量中,n的维度往往很大,远不止2维,而FM因子分解机能够处理n比较大的情况.

###Thinking2：FFM与FM有哪些区别？

最主要的区别在于FFM中有field的概念,而FM并没有.在FM算法中,每个特征有唯一的一个隐向量表示，这个隐向量被用来学习与其他任何特征之间的影响.
在FFM算法中,每个特征会有几个不同的隐向量，fj 是第 j 个特征所属的field.FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型
FFM中,每个特征有多个隐向量,使用哪个，取决于和哪个向量进行点乘.

###Thinking3:DeepFM相比于FM解决了哪些问题，原理是怎样的?

FM可以做特征组合，但是计算量大，一般只考虑2阶特征组合因为特征复杂度的原因.而DeepFM解决了这个问题:考虑到了高阶特征组合,这一部分由神经网络负责,并设计了一种end-to-end的模型结构,无需特征工程.
DeepFM=FM+DNN,在提取低阶特征时使用FM,既可以做1阶特征建模,也可以做2阶特征建模;提取高阶特征时,使用神经网络DNN,并且end-to-end共享特征输入.
DeepFM的公式:y=sigmoid(yFM+yDNN).FM部分:FM部分是一个分解机，因为加入了隐含变量，所以对于不出现或者极少出现的隐含变量也可以很好的学习。
神经网络部分是一个前馈网络，与图像这类输入不同，图像的输入一般是连续而且稠密的，然而这里用于推荐任务的输入一般是特别稀疏的。因此在该神经网络中，在第一层隐藏层之前，引入一个嵌入层(Embedding)，把输入向量压缩到低维稠密向量。

###Thinking4:Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？

baseline算法是基于统计的基准线打分,预测函数为bui=miu+bu+bi,即预测值=平均打分+用户对整体的偏差+商品对整体的偏差.最优化的是实际评分减去预测值之差的平方的累加和,并对用户对整体的偏差与商品对整体的偏差做惩罚处理.
baseline使用ALS优化时,第一步固定bu,优化bi;第二步,固定bi,优化bu;直到得到理想值.
Baselineonly和KNNbaseline的区别是:Baselineonly是仅仅只做预估,预估结束后就可以得到结论;KNNbaseline是先做预估,预估结束后再找邻域出结果,相当于两个模型KNN和Baseline的融合.

###Thinking5:基于邻域的协同过滤都有哪些算法，请简述原理

一共有两种算法:一种是Item CF,另一种是user CF.
UserCF主要分为三步:step1,找到和目标用户兴趣相似的用户集合,然后计算相似度,并取出top k的相似度;
step2,用户u对物品i的相似度，等价于K个邻居对物品i的兴趣度.通过step1得到的相似度与已知的用户v对item i的评分(兴趣)的乘积累加和得到用户u对商品i的评价.
step3,为用户u生成推荐列表:去掉用户u已喜欢过的商品,然后按评价从大到小排序.
Item CF也有3步:step1,计算物品之间的相似度; 
step2,用户u对物品i的兴趣度，等价于物品i的K个邻居物品，受到用户u的兴趣度.通过step1得到的item i与j的相似度与已知的用户v对item j的评分(兴趣)的乘积累加和得到用户u对商品i的评价.
step3,为用户u生成推荐列表:和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名
预测用户u对物品的兴趣度，去掉用户u已经喜欢过的物品，剩下按照从大到小进行推荐.




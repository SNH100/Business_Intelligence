{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features =20000\n",
    "maxlen = 200\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\",encoding='gbk',nrows=1000)\n",
    "test = pd.read_csv(\"./input/test.csv\",encoding='gbk',nrows=1000)\n",
    "data = pd.concat([train,test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "train = pd.read_csv(\"./input/train_chi.csv\",encoding='gbk')\n",
    "# 建立tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_features,lower=True)\n",
    "tokenizer.fit_on_texts(list(data['text']))\n",
    "#word_index = tokenizer.word_index\n",
    "x_train = tokenizer.texts_to_sequences(list(train['text']))\n",
    "x_train = pad_sequences(x_train,maxlen=maxlen) # padding\n",
    "y_train = list(train['target'])\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.3,random_state=0)\n",
    "# del train\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Deeds are the Reason of this earthquake May ALLAH Forgive us all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our', 'Deeds', 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Our','Deeds',0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer.texts_to_sequences(list(test['text']))\n",
    "x_test = pad_sequences(x_test,maxlen=maxlen) # padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_matrix=None):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding(max_features, embed_size)(inp)\n",
    "    else:\n",
    "        x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "#     x = GlobalMeanPool1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)   \n",
    "    x = Dense(128, activation=\"relu\")(x)  \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 70s 6s/step - loss: 0.6852 - accuracy: 0.5637 - val_loss: 0.6723 - val_accuracy: 0.5858\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.6521 - accuracy: 0.5935 - val_loss: 0.5732 - val_accuracy: 0.7377\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 79s 7s/step - loss: 0.4910 - accuracy: 0.7851 - val_loss: 0.4790 - val_accuracy: 0.7933\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 81s 7s/step - loss: 0.3404 - accuracy: 0.8660 - val_loss: 0.4815 - val_accuracy: 0.8025\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 81s 7s/step - loss: 0.2660 - accuracy: 0.8951 - val_loss: 0.5692 - val_accuracy: 0.7894\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "history = model.fit(x_train, y_train, batch_size=512, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(embeddings_index,word_index):\n",
    "    embedding_matrix = np.zeros((max_features, 300))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        try:\n",
    "     \n",
    "            embedding_vector = embeddings_index[word]\n",
    "        except:\n",
    "           \n",
    "            embedding_vector = embeddings_index[\"unknown\"]\n",
    "        if embedding_vector is not None:\n",
    "            # 保证embedding_matrix行的向量与word_index中序号一致\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 8221/8221 [00:00<00:00, 183177.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "EMBEDDING_FILE = './pretrain/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE,encoding='utf-8'))\n",
    "glove_embedding_matrix = build_matrix(embeddings_index,tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 134s 12s/step - loss: 0.6378 - accuracy: 0.6465 - val_loss: 0.5259 - val_accuracy: 0.7666\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 142s 13s/step - loss: 0.4766 - accuracy: 0.7885 - val_loss: 0.4672 - val_accuracy: 0.7929\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 250s 23s/step - loss: 0.4168 - accuracy: 0.8174 - val_loss: 0.4591 - val_accuracy: 0.7968\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 186s 17s/step - loss: 0.3748 - accuracy: 0.8411 - val_loss: 0.5785 - val_accuracy: 0.7342\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 138s 13s/step - loss: 0.3632 - accuracy: 0.8467 - val_loss: 0.4810 - val_accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "model = build_model(glove_embedding_matrix)\n",
    "history = model.fit(x_train, y_train, batch_size=512, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lstm的五折"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9/9 [==============================] - 111s 12s/step - loss: 0.6421 - accuracy: 0.6418 - val_loss: 0.5751 - val_accuracy: 0.7308\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 109s 12s/step - loss: 0.5053 - accuracy: 0.7722 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 113s 13s/step - loss: 0.4357 - accuracy: 0.8091 - val_loss: 0.4998 - val_accuracy: 0.7814\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 113s 13s/step - loss: 0.3974 - accuracy: 0.8285 - val_loss: 0.4643 - val_accuracy: 0.7899\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 110s 12s/step - loss: 0.3538 - accuracy: 0.8489 - val_loss: 0.4558 - val_accuracy: 0.8011\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "2/2 [==============================] - 3s 2s/step\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 109s 12s/step - loss: 0.6365 - accuracy: 0.6449 - val_loss: 0.5564 - val_accuracy: 0.7627\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 108s 12s/step - loss: 0.5049 - accuracy: 0.7757 - val_loss: 0.4975 - val_accuracy: 0.7730\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 108s 12s/step - loss: 0.4405 - accuracy: 0.8069 - val_loss: 0.4604 - val_accuracy: 0.7899\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 108s 12s/step - loss: 0.3946 - accuracy: 0.8318 - val_loss: 0.4724 - val_accuracy: 0.7983\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 117s 13s/step - loss: 0.3559 - accuracy: 0.8485 - val_loss: 0.4899 - val_accuracy: 0.7955\n",
      "3/3 [==============================] - 3s 1s/step\n",
      "2/2 [==============================] - 3s 2s/step\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 111s 12s/step - loss: 0.6404 - accuracy: 0.6510 - val_loss: 0.5444 - val_accuracy: 0.7458\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 109s 12s/step - loss: 0.5205 - accuracy: 0.7596 - val_loss: 0.4461 - val_accuracy: 0.8068\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 109s 12s/step - loss: 0.4510 - accuracy: 0.7976 - val_loss: 0.4194 - val_accuracy: 0.8189\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 124s 14s/step - loss: 0.4002 - accuracy: 0.8250 - val_loss: 0.4120 - val_accuracy: 0.8246\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 125s 14s/step - loss: 0.3609 - accuracy: 0.8478 - val_loss: 0.4114 - val_accuracy: 0.8302\n",
      "3/3 [==============================] - 3s 1s/step\n",
      "2/2 [==============================] - 3s 2s/step\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 105s 12s/step - loss: 0.6432 - accuracy: 0.6500 - val_loss: 0.5572 - val_accuracy: 0.7280\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 109s 12s/step - loss: 0.5002 - accuracy: 0.7793 - val_loss: 0.4589 - val_accuracy: 0.7927\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 122s 14s/step - loss: 0.4243 - accuracy: 0.8133 - val_loss: 0.4545 - val_accuracy: 0.7899\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 124s 14s/step - loss: 0.3820 - accuracy: 0.8388 - val_loss: 0.4889 - val_accuracy: 0.7842\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 138s 15s/step - loss: 0.3568 - accuracy: 0.8461 - val_loss: 0.5075 - val_accuracy: 0.7786\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "2/2 [==============================] - 3s 2s/step\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 124s 14s/step - loss: 0.6343 - accuracy: 0.6735 - val_loss: 0.5380 - val_accuracy: 0.7465\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 130s 14s/step - loss: 0.4852 - accuracy: 0.7817 - val_loss: 0.4900 - val_accuracy: 0.7775\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 132s 15s/step - loss: 0.4234 - accuracy: 0.8131 - val_loss: 0.4768 - val_accuracy: 0.7906\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 133s 15s/step - loss: 0.3818 - accuracy: 0.8316 - val_loss: 0.4854 - val_accuracy: 0.7869\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 120s 13s/step - loss: 0.3468 - accuracy: 0.8539 - val_loss: 0.4820 - val_accuracy: 0.7962\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "2/2 [==============================] - 3s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "skf = KFold(n_splits=5, random_state=1017, shuffle=True)\n",
    "score = []\n",
    "count = 0\n",
    "oof_pred = np.zeros((x_train.shape[0],1))\n",
    "sub = np.zeros((x_test.shape[0],1))\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    x1_tr, x1_va = np.array(x_train)[train_index], np.array(x_train)[test_index]\n",
    "    y_tr, y_va = np.array(y_train)[train_index], np.array(y_train)[test_index]\n",
    "    uid_tr, uid_va = train['id'][train_index], train['id'][test_index]\n",
    "    model = build_model(glove_embedding_matrix)\n",
    "    model.fit(x1_tr, y_tr, batch_size=512, epochs=5, validation_data=(x1_va, y_va))\n",
    "    oof_pred[test_index] = model.predict([x1_va],batch_size=512,verbose=1)\n",
    "    sub += model.predict([x_test],batch_size=512,verbose=1)/skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target']=sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0.654061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0.813033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>0.903884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>0.780918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>0.958763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "     target  \n",
       "0  0.654061  \n",
       "1  0.813033  \n",
       "2  0.903884  \n",
       "3  0.780918  \n",
       "4  0.958763  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
